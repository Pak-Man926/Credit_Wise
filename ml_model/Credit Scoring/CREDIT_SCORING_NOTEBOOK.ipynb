{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probability of default: credit scoring model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model uses a Kaggle dataset containing data about credit repayment difficulty rates among customers.\n",
    "\n",
    "**Kaggle description:**\n",
    "\n",
    "Improve on the state of the art in credit scoring by predicting the probability that somebody will experience financial distress in the next two years. \n",
    "\n",
    "Banks play a crucial role in market economies. They decide who can get finance and on what terms and can make or break investment decisions. For markets and society to function, individuals and companies need access to credit. \n",
    "\n",
    "Credit scoring algorithms, which make a guess at the probability of default, are the method banks use to determine whether or not a loan should be granted. This competition requires participants to improve on the state of the art in credit scoring, by predicting the probability that somebody will experience financial distress in the next two years.\n",
    "\n",
    "The goal of this competition is to build a model that borrowers can use to help make the best financial decisions.\n",
    "\n",
    "Historical data are provided on 250,000 borrowers.\n",
    "\n",
    "---\n",
    "\n",
    "The variables are the following:\n",
    "\n",
    "**SeriousDlqin2yrs** Person experienced 90 days past due delinquency or worse (Target variable / label)\n",
    "\n",
    "**RevolvingUtilizationOfUnsecuredLines**: Total balance on credit cards and personal lines of credit except real estate and no installment debt like car loans divided by the sum of credit limits\n",
    "\n",
    "**age** Age of borrower in years\n",
    "\n",
    "**NumberOfTime30-59DaysPastDueNotWorse**: Number of times borrower has been 30-59 days past due but no worse in the last 2 years.\n",
    "\n",
    "**DebtRatio**: Monthly debt payments, alimony,living costs divided by monthy gross income\n",
    "\n",
    "**MonthlyIncome**: Monthly income\n",
    "\n",
    "**NumberOfOpenCreditLinesAndLoans**: Number of Open loans (installment like car loan or mortgage) and Lines of credit (e.g. credit cards)\n",
    "\n",
    "**NumberOfTimes90DaysLate**: Number of times borrower has been 90 days or more past due.\n",
    "\n",
    "**NumberRealEstateLoansOrLines**: Number of mortgage and real estate loans including home equity lines of credit\n",
    "\n",
    "**NumberOfTime60-89DaysPastDueNotWorse**: Number of times borrower has been 60-89 days past due but no worse in the last 2 years.\n",
    "\n",
    "**NumberOfDependents**: Number of dependents in family excluding themselves (spouse, children etc.)\n",
    "\n",
    "---\n",
    "\n",
    "We will be using a random forest classifier for two reasons: firstly, because it would allow us to quickly and easily change the output to a simple binary classification problem. Secondly, because the predict_proba functionality allows us to output a probability score (probability of 1), this score is what we will use for predicting the probability of 90 days past due delinquency or worse in 2 years time.\n",
    "\n",
    "---\n",
    "\n",
    "Furthermore, we will predominantly be adopting a quantiles based approach in order to streamline the process as much as possible so that hypothetical credit checks can be returned as easily and as quickly as possible.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load in our libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import sklearn\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, StratifiedKFold, learning_curve\n",
    "from sklearn.feature_selection import SelectFromModel, SelectKBest\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.ensemble.gradient_boosting import GradientBoostingClassifier\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "\n",
    "sns.set(style='white', context='notebook', palette='deep')\n",
    "pd.options.display.max_columns = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"cs-training.csv\")\n",
    "kaggle_test = pd.read_csv(\"cs-test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SeriousDlqin2yrs is the target variable (label), it is binary.\n",
    "\n",
    "The training set contains 150,000 observations of 11 features and 1 label.\n",
    "\n",
    "All of our features are numerical in nature.\n",
    "\n",
    "NumberOfDependents and MonthlyIncome contain NaN values, we also suspect that other variables contains errors (Age)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_test.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test data also contains several NaN values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Target distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.countplot(x = train.SeriousDlqin2yrs ,palette=\"Set3\")\n",
    "sns.set(font_scale=1.5)\n",
    "ax.set_ylim(top = 150000)\n",
    "ax.set_xlabel('Financial difficulty in 2 years')\n",
    "ax.set_ylabel('Frequency')\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(10,5)\n",
    "ax.set_ylim(top=160000)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the distribution of our target variable is very skewed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detecting outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def detect_outliers(df,n,features):\n",
    "    outlier_indices = []\n",
    "    \n",
    "    # iterate over features(columns)\n",
    "    for col in features:\n",
    "        # 1st quartile (25%)\n",
    "        Q1 = np.percentile(df[col], 25)\n",
    "        # 3rd quartile (75%)\n",
    "        Q3 = np.percentile(df[col],75)\n",
    "        # Interquartile range (IQR)\n",
    "        IQR = Q3 - Q1\n",
    "        \n",
    "        # outlier step\n",
    "        outlier_step = 1.5 * IQR\n",
    "        \n",
    "        # Determine a list of indices of outliers for feature col\n",
    "        outlier_list_col = df[(df[col] < Q1 - outlier_step) | (df[col] > Q3 + outlier_step )].index\n",
    "        \n",
    "        # append the found outlier indices for col to the list of outlier indices \n",
    "        outlier_indices.extend(outlier_list_col)\n",
    "        \n",
    "    # select observations containing more than 2 outliers\n",
    "    outlier_indices = Counter(outlier_indices)        \n",
    "    multiple_outliers = list( k for k, v in outlier_indices.items() if v > n )\n",
    "    \n",
    "    return multiple_outliers\n",
    "\n",
    "# detect outliers from Age, SibSp , Parch and Fare\n",
    "# These are the numerical features present in the dataset\n",
    "Outliers_to_drop = detect_outliers(train,2,[\"RevolvingUtilizationOfUnsecuredLines\",\n",
    "                                            \"age\",\n",
    "                                            \"NumberOfTime30-59DaysPastDueNotWorse\",\n",
    "                                            \"DebtRatio\",\n",
    "                                            \"MonthlyIncome\",\n",
    "                                            \"NumberOfOpenCreditLinesAndLoans\",\n",
    "                                            \"NumberOfTimes90DaysLate\",\n",
    "                                            \"NumberRealEstateLoansOrLines\",\n",
    "                                            \"NumberOfTime60-89DaysPastDueNotWorse\",\n",
    "                                            \"Unnamed: 0\",\n",
    "                                            \"NumberOfDependents\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.loc[Outliers_to_drop]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We detected 3527 outliers in the training set, which represents 2.53% of our training data. We will drop these outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = train.drop(Outliers_to_drop, axis = 0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_len = len(train)\n",
    "dataset =  pd.concat(objs=[train, kaggle_test], axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.rename(columns={'Unnamed: 0': 'Unknown',\n",
    "                                  'SeriousDlqin2yrs': 'Target',\n",
    "                                  'RevolvingUtilizationOfUnsecuredLines': 'UnsecLines',\n",
    "                                  'NumberOfTime30-59DaysPastDueNotWorse': 'Late3059',\n",
    "                                  'DebtRatio': 'DebtRatio',\n",
    "                                  'MonthlyIncome': 'MonthlyIncome',\n",
    "                                  'NumberOfOpenCreditLinesAndLoans': 'OpenCredit',\n",
    "                                  'NumberOfTimes90DaysLate': 'Late90',\n",
    "                                  'NumberRealEstateLoansOrLines': 'PropLines',\n",
    "                                  'NumberOfTime60-89DaysPastDueNotWorse': 'Late6089',\n",
    "                                  'NumberOfDependents': 'Deps'})\n",
    "\n",
    "train = train.rename(columns={'Unnamed: 0': 'Unknown',\n",
    "                                  'SeriousDlqin2yrs': 'Target',\n",
    "                                  'RevolvingUtilizationOfUnsecuredLines': 'UnsecLines',\n",
    "                                  'NumberOfTime30-59DaysPastDueNotWorse': 'Late3059',\n",
    "                                  'DebtRatio': 'DebtRatio',\n",
    "                                  'MonthlyIncome': 'MonthlyIncome',\n",
    "                                  'NumberOfOpenCreditLinesAndLoans': 'OpenCredit',\n",
    "                                  'NumberOfTimes90DaysLate': 'Late90',\n",
    "                                  'NumberRealEstateLoansOrLines': 'PropLines',\n",
    "                                  'NumberOfTime60-89DaysPastDueNotWorse': 'Late6089',\n",
    "                                  'NumberOfDependents': 'Deps'})\n",
    "\n",
    "kaggle_test = kaggle_test.rename(columns={'Unnamed: 0': 'Unknown',\n",
    "                                  'SeriousDlqin2yrs': 'Target',\n",
    "                                  'RevolvingUtilizationOfUnsecuredLines': 'UnsecLines',\n",
    "                                  'NumberOfTime30-59DaysPastDueNotWorse': 'Late3059',\n",
    "                                  'DebtRatio': 'DebtRatio',\n",
    "                                  'MonthlyIncome': 'MonthlyIncome',\n",
    "                                  'NumberOfOpenCreditLinesAndLoans': 'OpenCredit',\n",
    "                                  'NumberOfTimes90DaysLate': 'Late90',\n",
    "                                  'NumberRealEstateLoansOrLines': 'PropLines',\n",
    "                                  'NumberOfTime60-89DaysPastDueNotWorse': 'Late6089',\n",
    "                                  'NumberOfDependents': 'Deps'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix\n",
    "g = sns.heatmap(train.corr(),annot=False, fmt = \".2f\", cmap = \"coolwarm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the Target has the highest correlation with age, previous late payments, and the number of dependants."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring UnsecLines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.UnsecLines.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset.UnsecLines = pd.qcut(dataset.UnsecLines.values, 5).codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore UnsecLines feature vs Target\n",
    "g  = sns.factorplot(x=\"UnsecLines\",y=\"Target\",data=dataset,kind=\"bar\", size = 6 , \n",
    "palette = \"muted\")\n",
    "g.despine(left=True)\n",
    "g = g.set_ylabels(\"Target probability\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can that there is an almost exponential relationship between this variable and our target."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore Age vs Survived\n",
    "g = sns.FacetGrid(dataset, col='Target')\n",
    "g = g.map(sns.distplot, \"age\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset.age = pd.qcut(dataset.age.values, 5).codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore age feature vs Target\n",
    "g  = sns.factorplot(x=\"age\",y=\"Target\",data=dataset,kind=\"bar\", size = 6 , \n",
    "palette = \"muted\")\n",
    "g.despine(left=True)\n",
    "g = g.set_ylabels(\"Target probability\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that age has an inverse relationship to default risk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring Late3059"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore UnsecLines feature vs Target\n",
    "g  = sns.factorplot(x=\"Late3059\",y=\"Target\",data=dataset,kind=\"bar\", size = 6 , \n",
    "palette = \"muted\")\n",
    "g.despine(left=True)\n",
    "g = g.set_ylabels(\"Target probability\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(dataset)):\n",
    "    if dataset.Late3059[i] >= 6:\n",
    "        dataset.Late3059[i] = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore UnsecLines feature vs Target\n",
    "g  = sns.factorplot(x=\"Late3059\",y=\"Target\",data=dataset,kind=\"bar\", size = 6 , \n",
    "palette = \"muted\")\n",
    "g.despine(left=True)\n",
    "g = g.set_ylabels(\"Target probability\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to very high standard deviations we decided to group customers who have 6 or more late payments together. We can see that this has boosted the predictive capacity and reduced the variance of Late3059"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Exploring DebtRatio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore Age vs Survived\n",
    "g = sns.FacetGrid(dataset, col='Target')\n",
    "g = g.map(sns.distplot, \"DebtRatio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.DebtRatio = pd.qcut(dataset.DebtRatio.values, 5).codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore DebtRatio feature quantiles vs Target\n",
    "g  = sns.factorplot(x=\"DebtRatio\",y=\"Target\",data=dataset,kind=\"bar\", size = 6 , \n",
    "palette = \"muted\")\n",
    "g.despine(left=True)\n",
    "g = g.set_ylabels(\"Target probability\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Exploring MonthlyIncome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.MonthlyIncome.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.heatmap(dataset[[\"MonthlyIncome\",\"Unknown\",\"UnsecLines\",\"OpenCredit\",\"PropLines\"]].corr(),cmap=\"BrBG\",annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.heatmap(dataset[[\"MonthlyIncome\",\"age\",\"DebtRatio\",\"Deps\",\"Target\"]].corr(),cmap=\"BrBG\",annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.heatmap(dataset[[\"MonthlyIncome\",\"Late3059\",\"Late6089\",\"Late90\"]].corr(),cmap=\"BrBG\",annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We can see that MonthlyIncome has no strong correlation with any other variable so we cannot accurately estimate the NaN values. Thus, we will fill the NaN with the median value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.MonthlyIncome.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Fill Embarked nan values of dataset set with 'S' most frequent value\n",
    "dataset.MonthlyIncome = dataset.MonthlyIncome.fillna(dataset.MonthlyIncome.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.MonthlyIncome = pd.qcut(dataset.MonthlyIncome.values, 5).codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore DebtRatio feature quantiles vs Target\n",
    "g  = sns.factorplot(x=\"MonthlyIncome\",y=\"Target\",data=dataset,kind=\"bar\", size = 6 , \n",
    "palette = \"muted\")\n",
    "g.despine(left=True)\n",
    "g = g.set_ylabels(\"Target probability\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring OpenCredit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.OpenCredit.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset.OpenCredit = pd.qcut(dataset.OpenCredit.values, 5).codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore DebtRatio feature quantiles vs Target\n",
    "g  = sns.factorplot(x=\"OpenCredit\",y=\"Target\",data=dataset,kind=\"bar\", size = 6 , \n",
    "palette = \"muted\")\n",
    "g.despine(left=True)\n",
    "g = g.set_ylabels(\"Target probability\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring Late90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.Late90.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore DebtRatio feature quantiles vs Target\n",
    "g  = sns.factorplot(x=\"Late90\",y=\"Target\",data=dataset,kind=\"bar\", size = 6 , \n",
    "palette = \"muted\")\n",
    "g.despine(left=True)\n",
    "g = g.set_ylabels(\"Target probability\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(dataset)):\n",
    "    if dataset.Late90[i] >= 5:\n",
    "        dataset.Late90[i] = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore DebtRatio feature quantiles vs Target\n",
    "g  = sns.factorplot(x=\"Late90\",y=\"Target\",data=dataset,kind=\"bar\", size = 6 , \n",
    "palette = \"muted\")\n",
    "g.despine(left=True)\n",
    "g = g.set_ylabels(\"Target probability\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring PropLines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.PropLines.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore DebtRatio feature quantiles vs Target\n",
    "g  = sns.factorplot(x=\"PropLines\",y=\"Target\",data=dataset,kind=\"bar\", size = 6 , \n",
    "palette = \"muted\")\n",
    "g.despine(left=True)\n",
    "g = g.set_ylabels(\"Target probability\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(dataset)):\n",
    "    if dataset.PropLines[i] >= 6:\n",
    "        dataset.PropLines[i] = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore DebtRatio feature quantiles vs Target\n",
    "g  = sns.factorplot(x=\"PropLines\",y=\"Target\",data=dataset,kind=\"bar\", size = 6 , \n",
    "palette = \"muted\")\n",
    "g.despine(left=True)\n",
    "g = g.set_ylabels(\"Target probability\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring Late6089"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore Late6089 feature quantiles vs Target\n",
    "g  = sns.factorplot(x=\"Late6089\",y=\"Target\",data=dataset,kind=\"bar\", size = 6 , \n",
    "palette = \"muted\")\n",
    "g.despine(left=True)\n",
    "g = g.set_ylabels(\"Target probability\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(dataset)):\n",
    "    if dataset.Late6089[i] >= 3:\n",
    "        dataset.Late6089[i] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore Late6089 feature quantiles vs Target\n",
    "g  = sns.factorplot(x=\"Late6089\",y=\"Target\",data=dataset,kind=\"bar\", size = 6 , \n",
    "palette = \"muted\")\n",
    "g.despine(left=True)\n",
    "g = g.set_ylabels(\"Target probability\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring Deps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.Deps.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.Deps = dataset.Deps.fillna(dataset.Deps.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.Deps.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore DebtRatio feature quantiles vs Target\n",
    "g  = sns.factorplot(x=\"Deps\",y=\"Target\",data=dataset,kind=\"bar\", size = 6 , \n",
    "palette = \"muted\")\n",
    "g.despine(left=True)\n",
    "g = g.set_ylabels(\"Target probability\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(dataset)):\n",
    "    if dataset.Deps[i] >= 4:\n",
    "        dataset.Deps[i] = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore DebtRatio feature quantiles vs Target\n",
    "g  = sns.factorplot(x=\"Deps\",y=\"Target\",data=dataset,kind=\"bar\", size = 6 , \n",
    "palette = \"muted\")\n",
    "g.despine(left=True)\n",
    "g = g.set_ylabels(\"Target probability\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final NaN check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building binary/dummy variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = pd.get_dummies(dataset, columns = [\"UnsecLines\"], prefix=\"UnsecLines\")\n",
    "dataset = pd.get_dummies(dataset, columns = [\"age\"], prefix=\"age\")\n",
    "dataset = pd.get_dummies(dataset, columns = [\"Late3059\"], prefix=\"Late3059\")\n",
    "dataset = pd.get_dummies(dataset, columns = [\"DebtRatio\"], prefix=\"DebtRatio\")\n",
    "dataset = pd.get_dummies(dataset, columns = [\"MonthlyIncome\"], prefix=\"MonthlyIncome\")\n",
    "dataset = pd.get_dummies(dataset, columns = [\"OpenCredit\"], prefix=\"OpenCredit\")\n",
    "dataset = pd.get_dummies(dataset, columns = [\"Late90\"], prefix=\"Late90\")\n",
    "dataset = pd.get_dummies(dataset, columns = [\"PropLines\"], prefix=\"PropLines\")\n",
    "dataset = pd.get_dummies(dataset, columns = [\"Late6089\"], prefix=\"Late6089\")\n",
    "dataset = pd.get_dummies(dataset, columns = [\"Deps\"], prefix=\"Deps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building our credit scoring model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = dataset[:train_len]\n",
    "Kaggle_test = dataset[train_len:]\n",
    "Kaggle_test.drop(labels=[\"Target\"],axis = 1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Kaggle_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Separate train features and label \n",
    "\n",
    "train[\"Target\"] = train[\"Target\"].astype(int)\n",
    "\n",
    "Y_train = train[\"Target\"]\n",
    "\n",
    "X_train = train.drop(labels = [\"Target\", \"Unknown\"],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=50, max_features='sqrt')\n",
    "clf = clf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = pd.DataFrame()\n",
    "features['feature'] = X_train.columns\n",
    "features['importance'] = clf.feature_importances_\n",
    "features.sort_values(by=['importance'], ascending=True, inplace=True)\n",
    "features.set_index('feature', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.plot(kind='barh', figsize=(20, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'n_estimators': 1000, 'random_state' : 20}\n",
    "    \n",
    "model = RandomForestClassifier(**parameters)\n",
    "model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Kaggle_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results_df = pd.read_csv(\"cs-test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = results_df.drop([\"RevolvingUtilizationOfUnsecuredLines\",\n",
    "                             \"age\",\n",
    "                             \"NumberOfTime30-59DaysPastDueNotWorse\",\n",
    "                             \"DebtRatio\",\n",
    "                             \"MonthlyIncome\",\n",
    "                             \"NumberOfOpenCreditLinesAndLoans\",\n",
    "                             \"NumberOfTimes90DaysLate\",\n",
    "                             \"NumberRealEstateLoansOrLines\",\n",
    "                             \"NumberOfTime60-89DaysPastDueNotWorse\",\n",
    "                             \"NumberOfDependents\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DefaultProba = model.predict_proba(Kaggle_test.drop([\"Unknown\"], axis=1))\n",
    "DefaultProba = DefaultProba[:,1]\n",
    "results_df.SeriousDlqin2yrs = DefaultProba\n",
    "\n",
    "results_df = results_df.rename(columns={'Unnamed: 0': 'Id',\n",
    "                                        'SeriousDlqin2yrs': 'Probability'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv(\"KAGGLE_CREDIT_SCORE.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model lead to an accuracy rate of 0.800498 on Kaggle's unseen test data.\n",
    "\n",
    "I deem this accuracy rate to be acceptable given that we used a relatively simple quantile based approach and in light of the fact that no parameter optimization was undertaken. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
